{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, io, json, urllib, numpy as np, codecs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    url=\"https://api.crossref.org/journals?rows=1\"\n",
    "    response = urllib.urlopen(url).read()\n",
    "    json_result=json.loads(response)\n",
    "    count=json_result['message']['total-results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url=\"https://api.crossref.org/journals?rows=1000&offset=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n"
     ]
    }
   ],
   "source": [
    "#f=codecs.open('journals.csv','w','utf-8')\n",
    "dic=[]\n",
    "for it in range(count/1000): # change\n",
    "    print it,\n",
    "    offset = it * 1000\n",
    "    url=base_url+str(offset)\n",
    "    response = urllib.urlopen(url).read()\n",
    "    json_result=json.loads(response)\n",
    "    items=json_result['message']['items']\n",
    "    for item in items:\n",
    "        if len(item['ISSN'])>0 and 'title' in item and 'publisher' in item: \n",
    "            journal={}\n",
    "            journal['e:title']=item['title'].strip()\n",
    "            journal['e:publisher']=item['publisher'] \n",
    "            journal['e:issn']=item['ISSN']\n",
    "            journal['e:subjects']=[]\n",
    "            for subject in item['subjects']:\n",
    "                journal['e:subjects'].append(subject['name'])\n",
    "            if journal not in dic:\n",
    "                dic.append(journal)\n",
    "dic_c=dic      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_subjects=[]\n",
    "for j in dic:\n",
    "    for s in j['e:subjects']: \n",
    "        if s not in unique_subjects: \n",
    "            unique_subjects.append(s)\n",
    "len(unique_subjects)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(unique_subjects).to_csv('d/unique_subjects.csv',header=False,index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dic)\n",
    "df.to_csv('d/journals.csv',index=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_issns=pd.read_csv('main_issns.csv',header=None)\n",
    "main_issns=main_issns[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_new=[]\n",
    "for j in dic:\n",
    "    j_id=j\n",
    "    if j['e:issn'][0] in main_issns:        \n",
    "        j_id['@id']=j['e:issn'][0]\n",
    "        dic_new.append(j_id)    \n",
    "    if len(j['e:issn'])>1:\n",
    "        if j['e:issn'][1] in main_issns:\n",
    "            j_id['@id']=j['e:issn'][1]\n",
    "            dic_new.append(j_id)    \n",
    "len(dic_new)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('d/road.tsv') as f:\n",
    "    road_lines = f.read().splitlines()\n",
    "road_lines=road_lines[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "road_urls=[issn[1:-1] for issn in road_lines]\n",
    "road_issns=[url[-9:] for url in road_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for journal in dic_new:\n",
    "    issn=journal['@id']\n",
    "    if journal['@id'] in road_issns:\n",
    "        journal['e:open']=1\n",
    "        journal['e:road_url']=road_urls[road_issns.index(issn)]\n",
    "        dic_new[i]=journal\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches=len(dic_new)/10000\n",
    "for s in range(batches+1):\n",
    "    dic_chunk=dic_new[10000*s:10000*(s+1)]\n",
    "    with open('jsonld/'+str(s)+'journals.jsonld', 'w') as outfile:\n",
    "        json.dump(dic_chunk, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
